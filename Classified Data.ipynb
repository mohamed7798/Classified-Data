{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2fc21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534bbbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.010953</td>\n",
       "      <td>1.034006</td>\n",
       "      <td>0.853116</td>\n",
       "      <td>0.622460</td>\n",
       "      <td>1.036610</td>\n",
       "      <td>0.586240</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>0.319752</td>\n",
       "      <td>1.117340</td>\n",
       "      <td>1.348517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.575529</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>0.941835</td>\n",
       "      <td>0.792882</td>\n",
       "      <td>1.414277</td>\n",
       "      <td>1.269540</td>\n",
       "      <td>1.055928</td>\n",
       "      <td>0.713193</td>\n",
       "      <td>0.958684</td>\n",
       "      <td>1.663489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.135470</td>\n",
       "      <td>0.982462</td>\n",
       "      <td>0.781905</td>\n",
       "      <td>0.916738</td>\n",
       "      <td>0.901031</td>\n",
       "      <td>0.884738</td>\n",
       "      <td>0.386802</td>\n",
       "      <td>0.389584</td>\n",
       "      <td>0.919191</td>\n",
       "      <td>1.385504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.084894</td>\n",
       "      <td>0.861769</td>\n",
       "      <td>0.407158</td>\n",
       "      <td>0.665696</td>\n",
       "      <td>1.608612</td>\n",
       "      <td>0.943859</td>\n",
       "      <td>0.855806</td>\n",
       "      <td>1.061338</td>\n",
       "      <td>1.277456</td>\n",
       "      <td>1.188063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.837460</td>\n",
       "      <td>0.961184</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.934399</td>\n",
       "      <td>0.424762</td>\n",
       "      <td>0.778234</td>\n",
       "      <td>0.907962</td>\n",
       "      <td>1.257190</td>\n",
       "      <td>1.364837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0    0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
       "1    0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
       "2    0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
       "3    1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
       "4    1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  1.010953  1.034006  0.853116  0.622460  1.036610  0.586240  0.746811   \n",
       "996  0.575529  0.955786  0.941835  0.792882  1.414277  1.269540  1.055928   \n",
       "997  1.135470  0.982462  0.781905  0.916738  0.901031  0.884738  0.386802   \n",
       "998  1.084894  0.861769  0.407158  0.665696  1.608612  0.943859  0.855806   \n",
       "999  0.837460  0.961184  0.417006  0.799784  0.934399  0.424762  0.778234   \n",
       "\n",
       "          PJF       HQE       NXJ  TARGET CLASS  \n",
       "0    0.643798  0.879422  1.231409             1  \n",
       "1    1.013546  0.621552  1.492702             0  \n",
       "2    1.154483  0.957877  1.285597             0  \n",
       "3    1.380003  1.522692  1.153093             1  \n",
       "4    0.646691  1.463812  1.419167             1  \n",
       "..        ...       ...       ...           ...  \n",
       "995  0.319752  1.117340  1.348517             1  \n",
       "996  0.713193  0.958684  1.663489             0  \n",
       "997  0.389584  0.919191  1.385504             1  \n",
       "998  1.061338  1.277456  1.188063             1  \n",
       "999  0.907962  1.257190  1.364837             1  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:/ML and DL/ML/Data_csv/Classified Data',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edcd84e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WTT             float64\n",
       "PTI             float64\n",
       "EQW             float64\n",
       "SBI             float64\n",
       "LQE             float64\n",
       "QWG             float64\n",
       "FDJ             float64\n",
       "PJF             float64\n",
       "HQE             float64\n",
       "NXJ             float64\n",
       "TARGET CLASS      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1122a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WTT</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.949682</td>\n",
       "      <td>0.289635</td>\n",
       "      <td>0.174412</td>\n",
       "      <td>0.742358</td>\n",
       "      <td>0.940475</td>\n",
       "      <td>1.163295</td>\n",
       "      <td>1.721779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTI</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.114303</td>\n",
       "      <td>0.257085</td>\n",
       "      <td>0.441398</td>\n",
       "      <td>0.942071</td>\n",
       "      <td>1.118486</td>\n",
       "      <td>1.307904</td>\n",
       "      <td>1.833757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EQW</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.834127</td>\n",
       "      <td>0.291554</td>\n",
       "      <td>0.170924</td>\n",
       "      <td>0.615451</td>\n",
       "      <td>0.813264</td>\n",
       "      <td>1.028340</td>\n",
       "      <td>1.722725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBI</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.682099</td>\n",
       "      <td>0.229645</td>\n",
       "      <td>0.045027</td>\n",
       "      <td>0.515010</td>\n",
       "      <td>0.676835</td>\n",
       "      <td>0.834317</td>\n",
       "      <td>1.634884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LQE</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.032336</td>\n",
       "      <td>0.243413</td>\n",
       "      <td>0.315307</td>\n",
       "      <td>0.870855</td>\n",
       "      <td>1.035824</td>\n",
       "      <td>1.198270</td>\n",
       "      <td>1.650050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QWG</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.943534</td>\n",
       "      <td>0.256121</td>\n",
       "      <td>0.262389</td>\n",
       "      <td>0.761064</td>\n",
       "      <td>0.941502</td>\n",
       "      <td>1.123060</td>\n",
       "      <td>1.666902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDJ</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.963422</td>\n",
       "      <td>0.255118</td>\n",
       "      <td>0.295228</td>\n",
       "      <td>0.784407</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>1.134852</td>\n",
       "      <td>1.713342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PJF</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.071960</td>\n",
       "      <td>0.288982</td>\n",
       "      <td>0.299476</td>\n",
       "      <td>0.866306</td>\n",
       "      <td>1.065500</td>\n",
       "      <td>1.283156</td>\n",
       "      <td>1.785420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HQE</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.158251</td>\n",
       "      <td>0.293738</td>\n",
       "      <td>0.365157</td>\n",
       "      <td>0.934340</td>\n",
       "      <td>1.165556</td>\n",
       "      <td>1.383173</td>\n",
       "      <td>1.885690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NXJ</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.362725</td>\n",
       "      <td>0.204225</td>\n",
       "      <td>0.639693</td>\n",
       "      <td>1.222623</td>\n",
       "      <td>1.375368</td>\n",
       "      <td>1.504832</td>\n",
       "      <td>1.893950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET CLASS</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count      mean       std       min       25%       50%  \\\n",
       "WTT           1000.0  0.949682  0.289635  0.174412  0.742358  0.940475   \n",
       "PTI           1000.0  1.114303  0.257085  0.441398  0.942071  1.118486   \n",
       "EQW           1000.0  0.834127  0.291554  0.170924  0.615451  0.813264   \n",
       "SBI           1000.0  0.682099  0.229645  0.045027  0.515010  0.676835   \n",
       "LQE           1000.0  1.032336  0.243413  0.315307  0.870855  1.035824   \n",
       "QWG           1000.0  0.943534  0.256121  0.262389  0.761064  0.941502   \n",
       "FDJ           1000.0  0.963422  0.255118  0.295228  0.784407  0.945333   \n",
       "PJF           1000.0  1.071960  0.288982  0.299476  0.866306  1.065500   \n",
       "HQE           1000.0  1.158251  0.293738  0.365157  0.934340  1.165556   \n",
       "NXJ           1000.0  1.362725  0.204225  0.639693  1.222623  1.375368   \n",
       "TARGET CLASS  1000.0  0.500000  0.500250  0.000000  0.000000  0.500000   \n",
       "\n",
       "                   75%       max  \n",
       "WTT           1.163295  1.721779  \n",
       "PTI           1.307904  1.833757  \n",
       "EQW           1.028340  1.722725  \n",
       "SBI           0.834317  1.634884  \n",
       "LQE           1.198270  1.650050  \n",
       "QWG           1.123060  1.666902  \n",
       "FDJ           1.134852  1.713342  \n",
       "PJF           1.283156  1.785420  \n",
       "HQE           1.383173  1.885690  \n",
       "NXJ           1.504832  1.893950  \n",
       "TARGET CLASS  1.000000  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba20a732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAE9CAYAAAAI49kDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA06klEQVR4nO3debxcRZn/8c+XIEtwYREwEhiCBhQUI5soAiOLBlwCgiO4wDgq4g8U3IOMMzDKDCKIMjIwEaM4LsiISJTI6oAjskMICYEhRIRIJIOKwKBAcr+/P6qanHS67z23+3T3vd3P+/U6r9t9ljrVWarr1ql6HtkmhBBC/1ur1xUIIYTQHdHghxDCgIgGP4QQBkQ0+CGEMCCiwQ8hhAERDX4IIQyIjjX4kqZLukfSYkkzO3WfEEII5XSkwZc0ATgbOADYHjhc0vaduFcIIfTSSJ1bSS+TdL2kpyR9ssy1kjaWdKWke/PPjaqoa6d6+LsBi20vsf00cAEwo0P3CiGEnijZuf0D8FHg9FFcOxO42vZU4Or8vm2davC3AB4svF+a94UQQj8ZsXNre7ntm4FnRnHtDOD8/Pp84KAqKrt2FYU0oAb7VovhIOko4CiATd556M7Pf93uHapKCKGfLPnoJxq1L6My9LttS8eUmTDp3g+R26pslu1Z+XWjzu1rShY93LWb214GYHuZpM3K1nc4nWrwlwJbFt5PBh4qnpD/wGYBbHPWGRHQJ4TQNUMMlT632FY1MGLndhjtXNuSTg3p3AxMlTRF0jrAYcCcDt0rhBBGZaWHSm8jGLFz2+K1D0uaBJB/Li9Z5rA60uDbXgEcC1wOLAIutL2wE/cKIYTRGsKltxG007kd7to5wJH59ZHAJaP6gE10akgH23OBuZ0qP4QQWvWMV5Y+d/1hjtleIanWuZ0AzLa9UNLR+fi5kl4E3AI8HxiSdDywve3HGl2biz4VuFDS+4EHgHeM6gM20bEGP4QQxqoSPffSGnVubZ9beP070nBNqWvz/t8D+1ZWySwa/BDCwFnZ2WejY1bbY/iSJki6XdJP8/tpkm6QNE/SLZJ2a7+aIYRQnQrH8MeVKh7aHkd6MFtzGnCy7WnAP+T3IYQwZqy0S2/9pK0GX9Jk4M3AeYXdJj2cAHgB5acohRBCVwyNYusn7Y7hfwX4NPC8wr7jgcslnU76Qnldm/cIIYRKPd1nPfeyWu7hS3oLsNz2rXWHPgx8zPaWwMeAbzS5/qg8xn/LY7+6odVqhBDCqA1qD7+dIZ09gLdJup8U9GcfSd8hLRL4UT7nP0kBgtZge5btXWzvEnF0QgjdtBKV3vpJyw2+7RNsT7a9NWmF2M9tv4c0Zr93Pm0f4N62axlCCBUacvmtn3RiHv4Hga9KWhv4C6tHmQshhJ7rt557WZU0+LavAa7Jr38J7FxFuSGE0AnR4IcQwoB4xh1L5z2mtTsP/zhJCyQtzAGBavs/kvM0LpQUC69CCGPKStYqvfWTlnv4kl5BGq/fDXgauEzSpaQgQTOAHW0/VVWmlhBCqMqQY0hntF4O3GD7SQBJ1wIHA7sAp9p+ClI+x7ZrGUIIFRrUMfx2fl9ZAOwlaRNJE4EDSdlbtgX2lHSjpGsl7VpFRUMIoSorvVbprZ+0Mw9/EfBF4ErgMuAOYAXpt4aNgN2BT5GC+K/xdRorbUMIvfIME0pv/aStry/b37C9k+29gD+QFlktBX7k5CbS6uQXNrg2VtqGEHpiUHv4bU3LlLSZ7eWStgLeDryW1MDvA1wjaVtgHeCRtmsaQggVGYox/JZcJOku4CfAMbb/CMwGtpG0gBRj50h7QEPThRDGpCqnZUqanqehL5Y0s8FxSTorH58vaae8f7ucKKq2PVab3i7pJEm/LRw7sIrP3VYP3/aeDfY9DbynnXJDCKGTqhqqkTQBOBvYnzScfbOkObbvKpx2ADA1b68BzgFeY/seYFqhnN8CFxeuO9P26ZVUNOuvAaoQQihhiLVKbyPYDVhse0nu7F5AWodUNAP4dn6ueQOwoaRJdefsC9xn+zdVfL5mosEPIQycpz2h9FacUZi3YkDILYAHC++X5n2M8pzDgO/X7Ts2DwHNlrRRGx/3WSM2+Plmy/OYfP2xT0qypBfW7d9K0hOSPllFJUMIoUpDXqv0VpxRmLdZhaIaPf2tf2Y57DmS1gHeRsofUnMO8BLSkM8y4IxWPme9Mj38bwHT63dK2pI0bvVAg2vOBH7WVs1CCKFDKnxou5S04LRmMmvm8R7pnAOA22w/XNth+2HbK20PAV+nSSKp0Rrx09j+BWmOfb0zSflsV/s2k3QQsARYWEH9Qgihciut0tsIbgamSpqSe+qHAXPqzpkDHJFn6+wO/Mn2ssLxw6kbzqkb4z+YFNmgbS3N0pH0NuC3tu8oLqKVtAHwGVLPP4ZzQghjUomHsaXYXiHpWOByYAIw2/ZCSUfn4+cCc0mhZxYDTwLvq12fw9LsD3yorujTJE0jdajvb3C8JaNu8HMFTwTe2ODwyaSpRE80iKZQX85R5GxYm7zzUGK1bQihW6pcQWt7LqlRL+47t/DawDFNrn0S2KTB/vdWVsGCVnr4LwGmALXe/WTgNkm7keaYHppj4G8IDEn6i+2v1ReSH3zMAtjmrDNiYVYIoWuecX/FyClr1A2+7TuBZ2PcS7of2MX2I8Cehf0nAU80auxDCKGX+i2xSVllpmV+H7ge2E7SUknv73y1Qgihc4as0ls/GbGHb/vwEY5v3WT/Sa1VKYQQOmtQe/iRxDyEMHCG+izscVktrbSV9CpJ10u6U9JPJD0/799f0q15/62S9ulk5UMIoRXPeELprZ+0utL2PGCm7VeSort9Ku9/BHhr3n8k8B8V1TOEECqzEpXe+kmrK223A36RX18JHJLPvd12bcnwQmA9SetWVNcQQqjEaGLp9JNWP80CUrAfgHewepyImkOA220/1eI9QgihIwY1xWGrn+bvgGMk3Qo8D3i6eFDSDqQE502XA0cS8xBCrwyh0ls/aWmWju27yaEVct7aN9eOSZpMGtc/wvZ9w5QRK21DCD3Rbz33sloNnlZLXr4W8PfAuXn/hsClwAm2r6usliGEUKF+m31TVqsrbQ+X9D/A3aS4zt/Mpx8LvBT4XCH57mYNCw4hhB6JlbZNDLPS9qsNzv0C8IV2KxVCCJ1UVXjk8SZW2oYQBk6JxCZ9qcyQzpaS/kvSIkkLJR1Xd3yNvLaSTpC0WNI9kt7UiYqHEEKrYkinuRXAJ2zfJul5wK2SrrR9V6O8tpK2J6X52gF4MXCVpG1tr+xA/UMIYdTioW0TtpfZvi2/fhxYBGyRDzfKazsDuMD2U7Z/TUrrVUkC3hBCqMKg9vBH9eRC0tbAq4Ebi3lt607bAniw8H4pq74gQgih56oMrSBpeh6+XixpZoPjknRWPj5f0k6FY/fnYJPzJN1S2L+xpCsl3Zt/blTF5y7d4Et6LnARcDxpmOdE4B8andpgXyysCiGMGVWttJU0ATgbOADYnjRlffu60w4ApubtKOCcuuNvsD3N9i6FfTOBq21PBa7O79tWqsGX9BxSY/9d2z9i9by297Mqr+2LSD36YmydyaS5+vVlRmiFEEJPrLRKbyPYDVhse4ntp4ELSMPaRTOAbzu5AdhQ0qQRyp0BnJ9fnw8cNKoP2ESZWToCvgEssv1lSHltbW9me+uc8WopsJPt3wFzgMMkrStpCulb7ab6cm3Psr2L7V2e/7rdq/gsIYRQSoVDOmWGsIc7x8AVOX/IUYVzNre9DNJzVAp5xNtRZpbOHsB7gTslzcv7Pmt7bqOTbS+UdCFwF2no55iYoRNCGEtWjCKWTm6Ii43xrBwLDMoNYQ93zh62H8oRCa6UdHcOSd8RZVba/pLGFS6es3Xd+1OAU9qqWQghdMhoZt8UAz02UGYIu+k5tfwhOTbZxaQhol8AD0uaZHtZHv5ZXrrCwxjM9cUhhIFW4ZDOzcBUSVMkrUNagzSn7pw5wBF5ts7uwJ9yQ75BXtuEpA1IEYgXFK45Mr8+Erik/U8doRVCCAOoqvn1tldIOha4HJgAzM7D2kfn4+cCc4EDSWuSngTely/fHLg4PSZlbeB7ti/Lx04FLszBKh8gJZpq24gNfl5N+23gRcAQafzqq5KmkcIir0caq/9/tm/KM3rOA3bK5X/b9r9UUdkQQqhClYlN8vPMuXX7zi28NnBMg+uWAK9qUubvgX0rq2TWcmgF4DTgZNs/k3Rgfv/XpG+idW2/UtJE4C5J37d9f9WVDyGEVvTbCtqyyjy0XQbUpgc9LqkWWsHA8/NpL2DVgwoDG0haG1iflP7wsYrrHUIILVsxNJiPL0c1hl8MrUBacXu5pNNJD39fl0/7IWnRwDJgIvAx23+oqL4hhNC2Qe3htxRawfZjwIdJjfmWwMdIi7MgTStaSYqUOQX4hKRtGpQXK21DCD0xqEnMWw2tAGmqUO31f7IqIua7gMtsP2N7OXAdUIwRAcRK2xBC70S0zCYahVbIHgL2zq/3Ae7Nrx8A9slzTjcAdiflvg0hhDFhUBv8lkMrAB8Evpofzv6FVUuPzyYlNV9AWqH7Tdvzq6x0CCG0Ix7aNjFCaIWdG5z/BBUtEgghhE5wn/Xcy4qVtiGEgdNvD2PLKjOGv56kmyTdkZOYn5z3fz5nb5kn6QpJLy5cs6Ok6/P5d0par5MfIoQQRmNQx/DLDGQ9Bexj+1XANGB6DgD0Jds72p4G/JSc/SqP6X8HONr2DqTVt89UX/UQQmiNrdJbPykzhm/gifz2OXlznotfswGr4ju/EZhfy3WbY0KEEMKY0W8997JKjeHnvI23Ai8FzrZ9Y95/CnAE8CfgDfn0bQFLuhzYFLjA9mlVVzyEEFq1ckBn6ZT61LZX5qGbycBukl6R95+YV9p+Fzg2n7428Hrg3fnnwZLWiPoWK21DCL1il9/6yai+5mw/ClwDTK879D3gkPx6KXCt7UdsP0kKG7pTg7JipW0IoScitEITkjaVtGF+vT6wH3C3pKmF097GqtW0lwM7SpqYH+DuTcpvG0IIY0I8tG1uEnB+HsdfC7jQ9k8lXSRpO1JSlN8AtQwvf5T0ZVLqLwNzbV/ameqHEMLoxUPbJnJYhFc32H9Ig9Nrx75DmpoZQghjTr+NzZcVK21DCANnKGbphBDCYKhypa2k6ZLukbRY0swGxyXprHx8vqSd8v4tJf2XpEU5KsFxhWtOkvTbHMlgXk4j27Z2QitMk3RDrswtknaru24rSU9I+mQVFQ0hhKpUNS0zP9s8GzgA2B44XNL2dacdAEzN21HAOXl/LV/4y0lh5I+pu/ZM29PytlqS9Fa1E1qhlsR8GimsQv3iqjOBn1VRyRBCqFKFs3R2AxbbXmL7aeACUorXohnAt53cAGwoaZLtZbZvS/Xx40AtX3jHjNjg50quEVqB5knMkXQQsARYWGVlQwihCqNp8IuLRPN2VKGoLYAHC++XsmajPeI5dfnCa47NQ0CzJW3U7meG8ikOJ+TkJ8uBK3NoheOBL0l6EDgdOCGfuwHwGeDkKioYQghVG80YfnGRaN5mFYpq9CtA/UDQsOc0yBcOadjnJaRRlWXAGa1+1qJ2Qis0S2J+Mmns6YmGhWURWiGE0DMexTa8pcCWhfeTKYx2jHROk3zh2H44t7tDwNdZlTO8Le2EVmiWxPw1wGmS7if9FvBZScdSJ0IrhBB6pcIx/JuBqZKmSFoHOAyYU3fOHOCIPFtnd+BPtpcNky8cSZMKbw8mpYxt24jz8CVtCjxj+9FCaIUvsiqJ+TUUkpjb3rNw7UnAE7a/VkVlQwihClUtvLK9IndoLwcmALNtL5RUizxwLime2IHAYuBJ4H358ob5wvOMnNMkTSP9jnE/8KEq6ttOaIVHaZzEPIQQxrQqY+TkBnpu3b5zC68NHNPguqb5wm2/t7IKFrQTWuGXNEhiXnfOSS3XLIQQOiVi6YQQwmDwUK9r0BulH9rmqZm3S/ppft8wibmk/SXdmpOX3yppn05VPoQQWjGo4ZFHM0vnONJKsJqGScyBR4C32n4laSbPf1RR0RBCqEx10zLHlbILryYDbwbOq+1rlsTc9u22a/NQFwLrSVq3muqGEEL7BrWHX3YM/yvAp4HnFXc2SWJedAhwu+2n2qhjCCFUq8967mWViZb5FmC57VvrjzVJYl67bgfSfP2G80djpW0IoXc0iq1/lBnS2QN4W145ewGwj6T6bFbFJOa1IaCLgSNs39eo0FhpG0LomaFRbH2kTLTME2xPtr01adnwz22/p1kS85zw/FLgBNvXVV/lEEJok1V+6yPtzMM/tVESc9LQzkuBz0n6XN73RtvL27hXCCFUJnLalmD7GlLsnKZJzG1/AfhCuxULIYSOiQY/hBAGRJ8N1ZQVDX4IYeCozx7GltVOaIWmScwlnZAztN8j6U2dqHgIIbRsQB/athNaoWES85x1/TBgB1KilH/LoZVDCGFsiNAKzTUKrUDzJOYzgAtsP2X716Sg/5Wk5wohhEoMaIPfTmiF44HLJZ1O+uJ4Xd6/BVBcOtsoi3sIIfROnzXkZbUTWqFZEvMyWdwjtEIIoXdiDL+pZqEVmiUxL5PFPUIrhBB6RkPltxHLkqbnCSqLJc1scFySzsrH50vaaaRrJW0s6UpJ9+afG1XxuVsOrcCqJOZQSGJOytB+mKR1JU0BpgI3VVHZEEIYS/KElLOBA4DtgcPzxJWiA0jt4FRS7u9zSlw7E7ja9lTg6vy+be3Mw/8gDZKY54ztFwJ3ASuAY2yvbLumIYRQEVU3hr8bsNj2EgBJF5AmrtxVOGcG8O2czPwGSRtKmgRsPcy1M4C/ztefT4pw8Jl2K9tOaIWmScxtnwKc0mbdQgihM0YxNi/pKHKHNptle1Z+vQXwYOHYUuA1dUU0OmeLEa7d3PYyANvLJG1WusLDiJW2IYTBM4oefm7cZzU5XGaSSrNzSk1wqVLZefj356Tk8yTdkvd9SdLd+SHExTksMpKeI+n8fP4iSSd0sP4hhDB61c3DLzNJpdk5w137cB72If+sJNrwaFbavsH2NNu75PdXAq+wvSPwP0CtYX8HsG5OYr4z8CFJW1dR2RBCqEKFs3RuBqZKmiJpHdLEljl158wBjsizdXYH/pSHa4a7dg5pJiT55yVtf2jaGNKxfUXh7Q3AobVDwAb5Ye76wNPAY4QQwlhR0cCJ7RWSjgUuByYAs/PElaPz8XOBucCBpKgDTwLvG+7aXPSpwIWS3g88QOpIt61sg2/gCkkG/r3wwKLm74Af5Nc/JD1hXgZMJC3O+kMVlQ0hhCpUOEsH23NJjXpx37mF1waOKXtt3v97YN/qapmUHdLZw/ZOpPmix0jaq3ZA0omk6Zffzbt2A1YCLwamAJ+QtE19gbHSNoTQM7HStjnbD+Wfy0nJyXcDkHQk8Bbg3flbDOBdwGW2n8nnXwfs0qDMWGkbQuiNAQ2eViaWzgaSnld7DbwRWCBpOmkhwNtsP1m45AFS+AXl83cnJzgPIYSxoMrQCuNJmTH8zYGLJdXO/57tyyQtBtYFrszHbrB9NGmp8DeBBaR5pt+0Pb8TlQ8hhFZUOYY/nozY4Odlv69qsP+lTc5/goqeKIcQQkdEgx9CCAMiGvzmcmjkx0mzb1bY3kXSD4Dt8ikbAo/mdIdI2hH4d1JGrCFgV9t/qbTmIYTQohjSGdkbbD9Se2P7nbXXks4A/pRfrw18B3iv7TskbQI8U1F9QwghtKjtIR2lJ7Z/Q4qJD2kWz3zbd8CzCwhCCGHM6LfZN2WVXXhVW2l7aw4VWrQn8LDtWgKUbQFLulzSbZI+XVVlQwihEgM6D79sD38P2w/lmMxXSrrb9i/yscOB79eV+XpgV1LciKsl3Wr76spqHUII7eizhrysdlfarg28nVVxdCCF/LzW9iN5QdZcYCfqRGiFEEKvyOW3ftLyStt8eD/gbttLC5dcDuwoaWL+Qtib1dN9ARFaIYTQQzGk01TDlbb52GGsPpyD7T9K+jIp1rOBubYvra7KIYTQnkF9aNvyStt87G+b7P8OaWpmCCGMPX3Wcy8rVtqGEAZOv43NlxUNfghh8Axog182ifmGkn6Yk5YvkvTaZknMC9dsJekJSZ/sSM1DCKFVA/rQtuzCq6+Skpq8jDSev4jmScxrzgR+VlVFQwihKt2alilpY0lXSro3/9yoyXnTJd0jabGkmYX9DTvWkraW9GdJ8/J2bqNy65WZlvl8YC/gGwC2n7b9qO0rbK/Ip90ATC5ccxCwBFhICCGMMV1MgDITuNr2VODq/H71ukgTSHlEDgC2Bw6XtH0+PFzH+j7b0/J2dJnKlOnhbwP8L/BNSbdLOi/Pxy/6O3JvPh/7DHBymQqEEELXdW9IZwZwfn59PnBQg3N2AxbbXmL7aeCCfB3DdaxbUabBX5u0UvYc268G/o/Ct1SDJOYnA2fmRChNxUrbEELPjKLBL7ZVeauPJzaczW0vA8g/N2twzhbAg4X3S/O+es92rLMpuRN+raQ9y1SmzCydpcBS2zfm9z8kN/iFJOb7FpKYvwY4VNJppDj5Q5L+YvtrxUJtzwJmAWxz1hl99mgkhDCWaRTnFtuqhmVJVwEvanDoxDaqs1qb2KBjvQzYyvbvJe0M/FjSDrYfG+5GZRZe/U7Sg5K2s30PsC9wVyGJ+d7FJOa2n/2mkXQS8ER9Yx9CCD1VYRfT9n7Njkl6WNIk28skTQKWNzhtKbBl4f1k4KFCGWt0rG0/BTyVX98q6T5SpOJbhqtr2Vk6HwG+K2k+MA34Z+BrwPNI0TNLPyUOIYRe62LwtDnAkfn1kcAlDc65GZgqaYqkdUgha+ZAmr1D6li/rdixlrRpftiLpG2AqaSJMsMqtfDK9jxgl7rdDZOY1113UpnyQwihq7oXS+dU4EJJ7wceAN4BIOnFwHm2D7S9QtKxpMCTE4DZtmszHL8GrEvqWAPckGfk7AX8k6QVpNSzR9v+w0iViZW2IYSB063QCjnj374N9j8EHFh4P5cUSr7+vIYda9sXAReNtj7trLT9QWHS//2S5uVz98+Zse7MP/cZofgQQuiuAV1pW7aHX1tpe2geY5rYLIk58Ajw1pwh6xWkX1MaTTEKIYSeiOBpTRRW2v4tpJW2wNOF46slMbd9e+HyhcB6ktbNT5VDCKH3BrTBr2KlbX0S86JDgNujsQ8hjCVdDK0wprS90pY1k5gDIGkH4IvAhxoVGittQwg9M6Bj+GUa/EYrbXeCpknMkTSZlOz8CNv3NSo0ctqGEHolkpg3Yft3wIOStsu79mVVUvI1kpjn8J2XAifYvq7a6oYQQgUGtIdfdpZObaXtOqTVXO/L+9dIYg4cS1qU9TlJn8v73mi70ZLiEELoOrnPWvKS2llp2zCJue0vAF9ot2IhhNAxg9nex0rbEMLg6bfZN2VFgx9CGDj99jC2rDIpDrcrhFCYJ+kxSccPl8Rc0gk5N+M9kt7U0U8QQgijNaAPbcvM0rmnljcR2Bl4kjTlsmGuxZyL8TBgB2A68G+1MJ4hhDAWxLTMcvYlJc79zTC5FmcAF9h+yvavgcWknI0hhDA2RA+/lEbTMGH1XItl8zOGEEJPRA9/BHkO/tuA/6zbX59rccT8jPm6CK0QQugJDbn01k9G08M/ALjN9sO1HYVci+8uJDEfNj9jTYRWCCH0TAzpjGi1IGnNci2ScjEeJmldSVNIuRZvqqKyIYRQhYiWOQxJE4H9gR8VdjdMYp5zMV5IirdzGXCM7ZWV1jqEENrRpR6+pI0lXSnp3vxzoybnTc/T2BdLmlnYf5Kk3xamxR9YODbq6e9lQys8CWxSt69pEnPbpwCnlCk7hBC6rYsPY2cCV9s+NTfkM0kjI6vqkqatn03qVC8FbpY0x3YtSOWZtk+vu6Y4/f3FwFWSth2pcz3aWTohhDDudfGh7Qzg/Pz6fOCgBufsBiy2vSRnFLwgXzdSuaOe/t7yStt87CP514mFkk7L+54j6fycxHyRpBNGukcIIXTVKIZ0ijMK83bUKO60ue1lAPnnZg3OGWkq+7E5osHswpBQS9PfRxzSsX0PMA2e/dXjt8DFkt5A+pbZ0fZTkmof5B3AurZfmcf+75L0fdv3j3SvEELohtEM6dieBcxqWpZ0FfCiBodOLFudRrfNP88BPp/ffx44g7TuqdT093qjDZ727EpbSV8CTq3lqy3EuzewQc6GtT4p4fljo7xPCCF0ToXx8G3v1+yYpIclTbK9TNIkoFFekKZT2eumwX8d+OlI1wynnZW22wJ7SrpR0rWSds37f0jKe7sMeAA43fYfRnmfEELomC6utJ0DHJlfHwlc0uCcm4GpkqbkBa6H5evIXxI1BwMLCuWOevp7Oytt1wY2AnYHPgVcKEmkBwcrSU+OpwCfkLRNg/JipW0IoTe6t/DqVGB/SfeSZuGcCiDpxZLmAuSYZMcClwOLgAvz9HaA0/Lz0PnAG4CP5Wtamv4+miGd+pW2S4Ef5RW2N0kaAl4IvAu4zPYzwHJJ15GyZS0pFlYcF9vmrDP6bD1bCGEs08ruNDm2f08aCq/f/xBwYOH9XGBug/PeO0zZo57+3vJKW+DHwD4AkrYF1gEeIQ3j7KNkA9JvAHePplIhhNBREVqhuSYrbWcD20haQJo3emTu7Z8NPJc01nQz8E3b8yutdQghtGFQo2W2s9L2aeA9Dc59gjQ1M4QQxqYKZ+mMJ5HTNoQwcPqt515WNPghhMEzoA1+2TH8j+XwCQskfV/SepLekfcNSdql7vwdJV2fj98pab3OVD+EEEZPK1166ydlYulsAXwU2MX2K4AJpIUBC4C3A7+oO39t4DvA0bZ3AP4aeKbaaocQQutkl976SdkhnbWB9SU9A0wEHrK9CCCttVrNG4H5tu+AZ+ehhhDC2NFf7XhpI/bwbf8WOJ00v34Z8CfbVwxzybaAJV0u6TZJn66mqiGEUBG7/NZHygzpbESKijmFFC5hA0lrTMcsWBt4PfDu/PNgSWusNIvQCiGEXhnUefhlHtruB/za9v/mcAk/Al43zPlLgWttP5Ln788Fdqo/KZKYhxB6JR7aNvcAsLukiTk42r6kAD/NXA7smM9fG9ibFOAnhBDGhhjSacz2jaSQx7cBd+ZrZkk6WNJS4LXApZIuz+f/EfgyKazCPFLAtUs7U/0QQmjBgMbSKRta4R+Bf6zbfXHeGp3/HdLUzBBCGHP6bbplWbHSNoQweAa0wW95pW3ev0YS88I1W0l6QtInO1HxEEJo2dAotj4yYg+/sNJ2e9t/lnQhKbXWb2icxLzmTOBnldc4hBDapKE+a8lLanmlLfBhGicxR9JBpAxX/1dpbUMIoQoxpNPYMCttGyYxz1muPgOc3LlqhxBCG7o0pCNpY0lXSro3/9yoyXnT8/D4YkkzC/t/IGle3u6XNC/v31rSnwvHzi1Tn3ZW2jZLYn4ycGZOhDJcubHSNoTQE10MnjYTuNr2VODq/H71ukgTSJkCDwC2Bw6XtD2A7XfanmZ7GnARq2cdvK92zPbRZSrTzkrbZ5OY276J9F34QuA1pEzr9wPHA5+VdGx9obHSNoTQM91beDUDOD+/Ph84qME5uwGLbS/JmQQvyNc9K3em/4bV84qPWpkx/GdX2gJ/Jq20vQWYT0pifk0xibntPQuVPAl4wvbX2qlkCCFUahQPbSUdBRxV2DXL9qySl29uexmA7WUNJrcAbAE8WHi/lNRxLtoTeNj2vYV9UyTdDjwG/L3t/x6pMiM2+LZvlFRbabsCuB2YRVqDNjsnMX+aVUnMQwhhbBvF2Hxu3Js28JKuAl7U4NCJJW+xRox51lzjezir9+6XAVvZ/r2knYEfS9rB9mPD3aidlbbQIIl53XUnlSk/hBC6qcqVtrb3a3of6WFJk3LvfhKwvMFpS4EtC+8nk2ZC1spYm5RsaufCPZ8CajMkb5V0H2kizS3D1bXUwqsQQugr3RvDnwMcmV8fCVzS4JybgamSpkhah5RRcE7h+H7A3baX1nZI2jQ/7EXSNsBU0lT4YUWDH0IYPEMuv7XnVGB/SfcC++f3SHqxpLkAtlcAx5IiDS8CLrS9sFDGYaz5sHYvYL6kO0jBLY+2/YeRKlNqSEfSccAHSWNNX7f9FUnvAE4CXg7sZvuWfG7tQ61DGtv/lO2fl7lPCCF0RZceN+YUr2skgLL9EHBg4f1cUu6QRmX8bYN9F5GmaY5KmdAKryA19ruRGvDLJF3KqiTm/153ySPAW20/lK+9nPQUOoQQxoYIrdDUy4EbcvYqJF0LHGz7tPx+tZNt3154uxBYT9K6tRAMIYTQc+0P1YxLZcbwFwB7Sdokz8U/kNWfKA/nEOD2aOxDCGOKh8pvfaRMLJ1FwBeBK4HLgDtI8/GHJWmHfN2HmhyP0AohhN6IFIfN2f6G7Z1s7wX8Abh3uPMlTSZlwzrC9n1NyozQCiGE3ujeLJ0xpewsnc1sL5e0FelB7WuHOXdD4FLgBNvXVVLLEEKoUp/13MsqOw//Ikl3AT8BjrH9x2ZJzEnzSV8KfK4QurNR/IgQQuiNoaHyWx8pG1phzwb7GiYxt/0F4AvtVy2EEDqkzxrysiKJeQhh8MSQTnOSjssJzBdKOr6wv2ESc0kn5Mwt90h6UwfqHUIIrRvQWTrtrLSdTIMk5jlTy2HADqQMWVdJ2tb2yg59hhBCGJ0+m31TVssrbYFdaJzEfAZwQd7/a0mLSV8W11dd+RBCaIVXDmb/s52Vtg2TmNM4e0vE0gkhjB0DOqTTzkrbZknMy2RviZW2IYTeGdBpme2stG2WxHzY7C2FMmOlbQihN6KH31zhgWxtpe33gR+TkphTTGJOytRymKR1JU0hZWK5qfKahxBCizw0VHrrJ2Xn4V8kaRPgGVattJ1N4yTmCyVdCNxFGvo5JmbohBDGlD7ruZfVzkrbp2mSxNz2KcAp7VUthBA6ZEBn6cRK2xDCwPGAzsOPJOYhhMHTpQQokjaWdKWke/PPjZqcN1vS8jxEXur6ViIaRIMfQhg4HnLprU0zgattTwWuzu8b+RYwvez1dRENpgP/JmnCSJWJBj+EMHi6l+JwBnB+fn0+cFDD6ti/IE15L3v9sxENbP8aqEU0GJ7tcbcBR433e8Rn6H35/fAZ4s+o8xtwFHBLYStdX+DRuvd/HObcrYEFZa4Hvga8p7D/G8ChI9VnvPbwj+qDe8Rn6H353bjHeC+/G/foxmdomQuLRPM2q3hc0lU5mnD9NqOD1SoV0aBezNIJIYQ22N6v2TFJD0uaZHuZpEnA8mbnNtHs+lIRDeqN1x5+CCGMB3OAI/PrI4FLKrq+pYgG47XBnzXyKWP+HvEZel9+N+4x3svvxj268Rl65VRgf0n3Avvn90h6saS5tZMkfZ8UQn47SUslvX+4620vBGoRDS6jZEQD5QH/EEIIfW689vBDCCGMUjT4IYQwIKLBDyGEATHmG3xJ3+p1Hdol6XhJu0qKabB9LP5+hyfpryS9oPD+DZK+KunjktbpZd0GxZh/aCvpNts7dfgej9N40YIA235+m+WfDrwOeBkwH/gVcB1wve1Gy6lHW/7Gwx2v6B4X2v6b/PqLtj9TOHaF7Te2Wf5kYGvbv8zvPw48Nx/+nu3F7ZRfKLOZp4D7gCvs1tbTF/+tSvpX2x9ppZxhyu/o30Eu5+3DHH4KWOKU9rSVsm8EDrb9kKRpwFXAvwA7As/Y/kAr5YbyxkOPZKKkV9N4ZRm2b6vgHhvbfqaCchqy/UmA3IvZhdT4/x3wdUmP2t6+zVvcSvrCarb6bps2y4c0z7dmf+AzhfebVlD+l4DvFt5/iDRdbyJwMvDuCu7xvGGObQTsS/p7+ZsWyy/++e/RYhnD6fTfAcBbhzm2NvBySb+y/dEWyl7fdm1x0HuA2bbPkLQWMK+F8sIojYcGfwvgDJo3ZvtUcI8bgY7+FpGtDzwfeEHeHgLubLdQ21PaLaPMbVo8VtZ2tn9aeP+k7TMAJP13BeVj++SRzpE0v51btHFtu+VXcm/b7xvueG6cW/03W/w/vA9wQr7nkNSwPxcqNh4a/MW2q2jUh9PRf22SZpHCmD5O+nL5FfBl23+s8B5rAyttW9KWwGtIf3bzKrpF7TettYD1C791ifRF1q716t7vW3i9SQXlA2ncGDiWNLwGsAj4mu1rAGzv2EbxL8tfGAJeUvjyqA0NtlM2dP7vAEn/CnzW9uN1+19G+nPaT1LTUAIj+HlOf7qM9BvVz3PZk0hpUkOHjYcGvxsPGTYdbnzX9pfbLH8rYF3gXuC3pDgYj7ZZ5rMkfRD4IvCEpM8DnwJuA14tabbtL1Zwm2VA7c/hd4XXtfftelzStrb/B1Y9d8gNzRMVlI+kN5OiDP5T3kT6zW62pGNtzx3u+hJe3ub1I+n030GtnHmSPmf7e5ImAieRwvJ+BsD2shbLPh54JzAJeH1hGPVFwIlt1DmUNB4e2q60PWJg/zbvsQw4h+bPCUYcCihxD5F6+a/L2ytI8a+vt/2PbZa9EHg9aYx6EfBXth/J/1lvtr1DW5XvAknTgbNIuZBrz2V2Bj4LHGf7ZxXc45pc1h11+3cE/tX23u3eox/k2CxfI/17ejFpCf8XbD9Z8X02AfYCHrB9a5Vlh8bGQw+/nTHVspbZ/qdO3sDpm3WBpEeBP+XtLaSkBW01+MDTeXjoj5IW234k3/NJSZX9qpx/9T4GqD1kvgU4t4pZQLYvyzNEPg3UHgguAN5ue0HzK0flRfWNfb73fEmbt1t4YbZXreNQ7E3VZgGdaPvqNu7Rsb+Dglq91yYNHy2qorGX9FNgpu0F+XPcRqr/SyTNsv2Vdu8RhjceGvwXDDdVzPaPKrhHp8fwP0rq1e8BPEOekgnMpoKHtqwaz10LWEdS7QG0WHNsvCWS9ga+Q6rzt1g1HPJfkg4C/sn2e9sofxpwh+0j2q5sc//X4rFSbDedBZTTz72CNBPpFa2U3+m/g3yPvwf+lvTF9ANJWwBflfQB4MO272qj+CmFL+/3AVfaPkLS80j/J77SRtmhhHHR4JN6ws1m6VTR4L9Z0vHAS0kN8Ddsr6ig3JqtgR8CH2tj/HM4y1g1k+l3wOmFY1WN7X4JeJvt2wv7LpF0MXAHcHGb5Z8HTJF0G+k//6+AG2w/1ma5RS+RNKfBflHB1FVJ6wFHk/4dzSdNO1wBkCMZ3pEfiraq038HkKZ3vrr20Nb2b4FDJR0AXER7zymKU5/3Bb6e7/G4pLZzCYaRjYcx/G4svPoB6R/jfwMHAL+xfVwH7rMfhV/Fbf+qonJ3Ax6sfZlIOhI4BLgfOKmihVd3NVsvkEO3btfqgqVCORNJQ1y15xy7kr6wrrP9/9opO5c/7Bi97WvbLL+j/4668Xcwwv3Xtf1UG9f/BLiCNGlhNqnH/6ik9Un/H8b8s6bxbjz08F8iaRdgXsW97qLtbb8SQNI3KJFIYDTyNMlLSNMybyX1KA+R9GdSMuL32j6vjVucC+yX77UXafXiR4BppMVLh7ZRdo0kbVQ/lTSv8l1RRUOTx4mvkXQzafrqHsARwPR2y85+bfuBispqpKP/jujC34GkfxjmsIHPt1H8+0mzo/YD3mn70bx/d+CbbZQbShoPDf5VpNkbtTnOlYYlyJ79VdP2ig4sAjkbOMv2t4o7JR1BGsuHNKTRqgmFP4t3ArNsXwRcJGleG+UWnQlcIemTrD6L5otUMPYq6V2kXv000gPOWqP/ettVDUv9mLzATtJFtg+pqNyaTv87Gu7v4MyK7tHoWcZE4AOk9RAtN/i2l5OGvOpdD7yw1XJDeWN+SKemLizBa/NWRVgCJK1k1T/02iKWJ6kuls7/2N62ybGlwE75P0Or5S8ApuVG5m7gKNu/qB2z3dJDwgb3eQtpFs0OpN7eXcCXbP+kgrKfAO4m/bbyi9p8/CpJut32q+tfV1h+R/8d5XsU/w4AFlLR30GDez0POI7UM78QOKOdf6d1ZU8A3ggcDrwJ+G/bVfwmGoYxHnr4NR0JSwDQ6Xn+NIlKqrRM/c8V/Cf6PnCtpEeAP5PGkJH0UtL0z0o4hT74af1+ScdXMKXuBcCrSF/oJ0najvQw+nrSb3M/b7N8WH2aZOU9nS78O2r6d1ClPET0cVL8ovNJHZJKVoXnIcd3AW8mDXntQRrLr3SOf2hszPfwtWZYghtIszcqC0vQaZLOJEV+PN72/+V9G5B+Df9zFQ/2JO1OWsF4ReEe2wLPdTUB5oa79wO2t6q4zM1Jzx4+RmoQ2m5MCz3wYu8bKuyBd1Ke4dP0P6xbC2hWf48vAW8nPfs523Ylq5xz2UuBB0iLHH+cZ+f82t2JBRUYHz38joYl6JJPkx6k/kbSb0j/af+K1Hv6bBU3sH1Dg32VD4s00fZgdV7t+rrCtg7py/1fSc9s2taNHniH3VJ4fTLtL9hr5BOkZyh/D5xYeA5RxZfiRaQQDe8EVkq6hO6ETgnZmO/hQ2fDEnRTnn72UtJ/nsX98mtsFT38wvz7G1k1VHd3O9MA+1knnkF0Q/6//AbS2P2BpGHa9wNzq/xtIjQ25jNeQepW5BV6c4GfkRqGl5AeKI15kj4NYPvPwMtsz6819pL+uaeVK0nS45Iea7A9Toq30q7dgZWkGVm1laRLJM3M9x93jVuHjf2eWgP5//LPbX+QtCDxXaRe//09rNbAGPM9/GHCElwH3NnJhSZV0eqZkFZbSNaNhWXjgaSzSOPqH6+t8pT0fNKq4ZXA9BjrXaXf/t1IOsH2v/S6Hv1uPIzhb01nwxJ0g5q8bvR+UB0ITHWhB2L7MUkfBh4hrVwdaFo9FedESbWwE+PiofMIPkx6zhU6aMw3+LaHy0M6Xgw3HXBs/4rVPUNu8Oum7ZWS/rfRQ+lB42GCs/WB6Ph0wZhv8PvEq3JvTKTIlsWeWSXRLPvAXZKOsP3t4k5J7yHF+A/9LTo+XTDmx/DDYFAKw/sj0sKxWlL2XUnj+gc7RW0M41jdkNRqh0gJzqMD2mHR4IcxRdI+pCm4Aha6jWQhIYTVRYMfQugKSbsCL3RdukpJbwUecqQ57LhxMQ8/hNAXvkTj5zGL8rHQYdHghxC6ZRPb99fvtL2YFHo5dFg0+CGEbll/mGMbdK0WAywa/BBCt1wl6RTVZYaRdDJQRfjrMIJ4aBtC6IocEvw8Ut7ieXn3q0hRQD8QwdM6Lxr8EEJXSdqGQsYu20t6WZ9BEg1+CCEMiBjDDyGEARENfgihKyRF6IQeiwY/hNAtN/W6AoMuGvwQQrdECOQei1+xQgjdsqmkpvktbH+5m5UZRNHghxC6ZQLwXKKn3zMxLTOE0BX9lod3PIox/BBCt0TPvseiwQ8hdMuzScolTSkekPT27ldn8MSQTgihK4pDOvXDOzHc0x3Rww8hdIuavG70PnRANPghhG5xk9eN3ocOiGmZIYRu2UbSHFJvvvaa/H5K88tCVWIMP4TQFZL2Hu647Wu7VZdBFQ1+CCEMiBjDDyF0haQZko4pvL9R0pK8HdrLug2KaPBDCN3yaWBO4f26wK7AXwMf7kWFBk08tA0hdMs6th8svP+l7d8Dv8/5bkOHRQ8/hNAtGxXf2D628HbTLtdlIEWDH0LolhslfbB+p6QPEclRuiJm6YQQukLSZsCPgaeA2/LunUlj+QfZfrhHVRsY0eCHELpK0j7ADvntQts/72V9Bkk0+CGEnpK0IXCM7VN6XZd+F2P4IYSukLSlpFmSfirpA5ImSjoDuBfYrNf1GwQxLTOE0C3fBq4FLgKmAzcAC4FX2v5dLys2KGJIJ4TQFZLusP2qwvuHga1sP9XDag2U6OGHELpG0kasin3/O2BibdGV7T/0rGIDInr4IYSukHQ/METjZCe2vU13azR4osEPIYQBEbN0Qgg9I+klkk6UtKDXdRkE0eCHELpK0iRJx0u6iTRLZ23g8B5XayDEkE4IoStyHJ3DgcnAhXm7xHakN+ySaPBDCF0h6WngeuATtm/J+5bEw9ruiWmZIYRumQwcAnxZ0uakHv5zelulwRJj+CGEbrnM9jm29wL2Bf4ELJe0SNI/97huAyEa/BBCtzw7/972Utun294ZmEEKmRw6LIZ0Qgjdsqmkjzc59nhXazKgosEPIXTLBOC5NFlp2+W6DKSYpRNC6ApJt9neqdf1GGQxhh9C6JZGPfvQRdHDDyF0haSNIyJmb0WDH0IIAyKGdEIIYUBEgx9CCAMiGvwQQhgQ0eCHEMKA+P9JkBCUoiwXKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e9d815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WTT             0\n",
       "PTI             0\n",
       "EQW             0\n",
       "SBI             0\n",
       "LQE             0\n",
       "QWG             0\n",
       "FDJ             0\n",
       "PJF             0\n",
       "HQE             0\n",
       "NXJ             0\n",
       "TARGET CLASS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab986ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd5b184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
       "1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
       "2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
       "3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
       "4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
       "\n",
       "        PJF       HQE       NXJ  TARGET CLASS  \n",
       "0  0.643798  0.879422  1.231409             1  \n",
       "1  1.013546  0.621552  1.492702             0  \n",
       "2  1.154483  0.957877  1.285597             0  \n",
       "3  1.380003  1.522692  1.153093             1  \n",
       "4  0.646691  1.463812  1.419167             1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dde735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of outliers in WTT :  0\n",
      "number of outliers in PTI :  0\n",
      "number of outliers in EQW :  3\n",
      "number of outliers in SBI :  6\n",
      "number of outliers in LQE :  2\n",
      "number of outliers in QWG :  1\n",
      "number of outliers in FDJ :  3\n",
      "number of outliers in PJF :  0\n",
      "number of outliers in HQE :  0\n",
      "number of outliers in NXJ :  7\n"
     ]
    }
   ],
   "source": [
    "from datasist.structdata import detect_outliers\n",
    "\n",
    "feature_df = df[['WTT','PTI','EQW','SBI','LQE','QWG','FDJ','PJF','HQE','NXJ']]\n",
    "\n",
    "for col in feature_df:\n",
    "    outliers = detect_outliers(df,0,[col])\n",
    "    print(f'number of outliers in {col} : ',len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2dea300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "for col in feature_df:\n",
    "    if col == 'TARGET CLASS':\n",
    "        pass\n",
    "    else:\n",
    "        outliers = detect_outliers(df,0,[col])\n",
    "        col_median = df[col].median()\n",
    "        df[col].iloc[outliers] = col_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c21e55ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of outliers in WTT :  0\n",
      "number of outliers in PTI :  0\n",
      "number of outliers in EQW :  0\n",
      "number of outliers in SBI :  2\n",
      "number of outliers in LQE :  0\n",
      "number of outliers in QWG :  0\n",
      "number of outliers in FDJ :  1\n",
      "number of outliers in PJF :  0\n",
      "number of outliers in HQE :  0\n",
      "number of outliers in NXJ :  0\n"
     ]
    }
   ],
   "source": [
    "for col in feature_df:\n",
    "    outliers = detect_outliers(df,0,[col])\n",
    "    print(f'number of outliers in {col} : ',len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e10f4914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: TARGET CLASS, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0052d2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50.0\n",
       "0    50.0\n",
       "Name: TARGET CLASS, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TARGET CLASS'].value_counts() * 100 / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "015ce0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['TARGET CLASS'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "239fbfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
       "1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
       "2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
       "3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
       "4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
       "\n",
       "        PJF       HQE       NXJ  TARGET CLASS  \n",
       "0  0.643798  0.879422  1.231409             1  \n",
       "1  1.013546  0.621552  1.492702             0  \n",
       "2  1.154483  0.957877  1.285597             0  \n",
       "3  1.380003  1.522692  1.153093             1  \n",
       "4  0.646691  1.463812  1.419167             1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2849bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "columns = ['WTT','PTI','EQW','SBI','LQE','QWG','FDJ','PJF','HQE','NXJ']\n",
    "df[columns] = scaler.fit_transform(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6b82f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123542</td>\n",
       "      <td>0.185907</td>\n",
       "      <td>-0.916368</td>\n",
       "      <td>0.354429</td>\n",
       "      <td>-1.048006</td>\n",
       "      <td>-2.314810</td>\n",
       "      <td>-0.799916</td>\n",
       "      <td>-1.482368</td>\n",
       "      <td>-0.949719</td>\n",
       "      <td>-0.691037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.084836</td>\n",
       "      <td>-0.430348</td>\n",
       "      <td>-1.029729</td>\n",
       "      <td>0.672375</td>\n",
       "      <td>-0.454331</td>\n",
       "      <td>-1.154495</td>\n",
       "      <td>-1.134798</td>\n",
       "      <td>-0.202240</td>\n",
       "      <td>-1.828051</td>\n",
       "      <td>0.637280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.788702</td>\n",
       "      <td>0.339318</td>\n",
       "      <td>0.314635</td>\n",
       "      <td>0.808061</td>\n",
       "      <td>2.042757</td>\n",
       "      <td>-0.870810</td>\n",
       "      <td>2.640317</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>-0.682494</td>\n",
       "      <td>-0.415568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.060193</td>\n",
       "      <td>-0.620475</td>\n",
       "      <td>0.672283</td>\n",
       "      <td>0.450784</td>\n",
       "      <td>-0.265450</td>\n",
       "      <td>1.780341</td>\n",
       "      <td>1.066491</td>\n",
       "      <td>1.241325</td>\n",
       "      <td>-1.089171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.139275</td>\n",
       "      <td>-0.640392</td>\n",
       "      <td>-0.710064</td>\n",
       "      <td>-0.037393</td>\n",
       "      <td>0.823920</td>\n",
       "      <td>-0.937694</td>\n",
       "      <td>0.612844</td>\n",
       "      <td>-1.472352</td>\n",
       "      <td>1.040772</td>\n",
       "      <td>0.263454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0 -0.123542  0.185907 -0.916368  0.354429 -1.048006 -2.314810 -0.799916   \n",
       "1 -1.084836 -0.430348 -1.029729  0.672375 -0.454331 -1.154495 -1.134798   \n",
       "2 -0.788702  0.339318  0.314635  0.808061  2.042757 -0.870810  2.640317   \n",
       "3  0.982841  1.060193 -0.620475  0.672283  0.450784 -0.265450  1.780341   \n",
       "4  1.139275 -0.640392 -0.710064 -0.037393  0.823920 -0.937694  0.612844   \n",
       "\n",
       "        PJF       HQE       NXJ  TARGET CLASS  \n",
       "0 -1.482368 -0.949719 -0.691037             1  \n",
       "1 -0.202240 -1.828051  0.637280             0  \n",
       "2  0.285707 -0.682494 -0.415568             0  \n",
       "3  1.066491  1.241325 -1.089171             1  \n",
       "4 -1.472352  1.040772  0.263454             1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2248164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = df[['WTT','PTI','EQW','SBI','LQE','QWG','FDJ','PJF','HQE','NXJ']]\n",
    "x = np.asarray(feature_df)\n",
    "y = np.asarray(df['TARGET CLASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1e2d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a18f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147   9]\n",
      " [  5 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       156\n",
      "           1       0.94      0.97      0.95       144\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(x_train,y_train)\n",
    "y_pred = log_model.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c0d5fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8566666666666667\n",
      "[[131  25]\n",
      " [ 18 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       156\n",
      "           1       0.83      0.88      0.85       144\n",
      "\n",
      "    accuracy                           0.86       300\n",
      "   macro avg       0.86      0.86      0.86       300\n",
      "weighted avg       0.86      0.86      0.86       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "dt = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a655c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where k is = 1\n",
      "accuracy is 0.9133333333333333\n",
      "------------------------------\n",
      "where k is = 2\n",
      "accuracy is 0.92\n",
      "------------------------------\n",
      "where k is = 3\n",
      "accuracy is 0.93\n",
      "------------------------------\n",
      "where k is = 4\n",
      "accuracy is 0.9333333333333333\n",
      "------------------------------\n",
      "where k is = 5\n",
      "accuracy is 0.9366666666666666\n",
      "------------------------------\n",
      "where k is = 6\n",
      "accuracy is 0.95\n",
      "------------------------------\n",
      "where k is = 7\n",
      "accuracy is 0.9466666666666667\n",
      "------------------------------\n",
      "where k is = 8\n",
      "accuracy is 0.9566666666666667\n",
      "------------------------------\n",
      "where k is = 9\n",
      "accuracy is 0.9466666666666667\n",
      "------------------------------\n",
      "where k is = 26\n",
      "accuracy is 0.9466666666666667\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "k = [1,2,3,4,5,6,7,8,9,int(m.sqrt(len(x_train)))]\n",
    "for item in k :\n",
    "    print(f'where k is = {item}')\n",
    "    model = KNeighborsClassifier(n_neighbors = item)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print('accuracy is {}'.format(accuracy_score(y_test,y_pred)))\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a0396d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9566666666666667\n",
      "[[148   8]\n",
      " [  5 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       156\n",
      "           1       0.95      0.97      0.96       144\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 8)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e1295c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.66666666666666\n",
      "[[139  17]\n",
      " [  8 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       156\n",
      "           1       0.89      0.94      0.92       144\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.92      0.92      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "271723a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel is linear\n",
      "accuracy_score is : 0.9533333333333334\n",
      "kernel is poly\n",
      "accuracy_score is : 0.6166666666666667\n",
      "kernel is rbf\n",
      "accuracy_score is : 0.94\n",
      "kernel is sigmoid\n",
      "accuracy_score is : 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "kernel = ['linear','poly','rbf','sigmoid']\n",
    "for item in kernel:\n",
    "    print(f'kernel is {item}')\n",
    "    if item == 'poly':\n",
    "        model = SVC(kernel = item,degree = 2)\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        print('accuracy_score is :',accuracy_score(y_test,y_pred))\n",
    "    elif item == 'rbf':\n",
    "        model = SVC(kernel = item,degree = 4)\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        print('accuracy_score is :',accuracy_score(y_test,y_pred))\n",
    "    else :\n",
    "        model = SVC(kernel = item)\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        print('accuracy_score is :',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acb5f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.33333333333334\n",
      "[[147   9]\n",
      " [  5 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       156\n",
      "           1       0.94      0.97      0.95       144\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel = 'linear')\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "609b3290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (accuracy): 0.9357142857142856\n",
      "Mean precision: 0.9179678773099826\n",
      "Mean recall: 0.9609602795358796\n",
      "Best parametes: {'metric': 'chebyshev', 'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;chebyshev&#x27;, n_jobs=-1, n_neighbors=10,\n",
       "                     weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;chebyshev&#x27;, n_jobs=-1, n_neighbors=10,\n",
       "                     weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='chebyshev', n_jobs=-1, n_neighbors=10,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "parameters = {'n_neighbors': [1, 2, 5, 10], 'weights': ['uniform', 'distance'], 'metric': ['manhattan', 'euclidean', 'chebyshev']}\n",
    "def grid_search(estimator, parameters, X, y):\n",
    "    \n",
    "    scoring = ['accuracy', 'precision', 'recall']\n",
    "    kf = KFold(5)\n",
    "    \n",
    "    clf = GridSearchCV(estimator, parameters, cv=kf, scoring=scoring, refit=\"accuracy\", n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    i = clf.best_index_\n",
    "    best_precision = clf.cv_results_['mean_test_precision'][i]\n",
    "    best_recall = clf.cv_results_['mean_test_recall'][i]\n",
    "    \n",
    "    print('Best score (accuracy): {}'.format(clf.best_score_))\n",
    "    print('Mean precision: {}'.format(best_precision))\n",
    "    print('Mean recall: {}'.format(best_recall))\n",
    "    print('Best parametes: {}'.format(clf.best_params_))\n",
    "    \n",
    "    return clf.best_estimator_\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "grid_search(KNeighborsClassifier(n_jobs=-1),parameters,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60a7d464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.0\n",
      "[[144  12]\n",
      " [  6 138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       156\n",
      "           1       0.92      0.96      0.94       144\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(metric = 'chebyshev', n_neighbors = 10, weights = 'distance')\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a03ec4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "params = {'C':[1,5,7] ,'kernel':['linear','poly','rbf','sigmoid']}\n",
    "grid_search = GridSearchCV(clf,param_grid = params,scoring = 'accuracy',cv = 5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac7edfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.33333333333334\n",
      "[[147   9]\n",
      " [  5 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       156\n",
      "           1       0.94      0.97      0.95       144\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C = 1, kernel = 'linear')\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0829b58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'n_estimators': 2000, 'random_state': 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "crossvalidation=KFold(n_splits=10,shuffle=True,random_state=1)\n",
    "ada=AdaBoostClassifier()\n",
    "search_grid={'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1],'random_state':[1]}\n",
    "search=GridSearchCV(estimator=ada,param_grid=search_grid,scoring='accuracy',n_jobs=1,cv=crossvalidation)\n",
    "search.fit(x_train,y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b35b40be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.0\n",
      "[[146  10]\n",
      " [  8 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       156\n",
      "           1       0.93      0.94      0.94       144\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(learning_rate = 0.01, n_estimators = 2000, random_state = 1)\n",
    "ada.fit(x_train,y_train)\n",
    "y_pred = ada.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "942f2b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "6 fits failed out of a total of 560.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 5007, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 2278, in _fit\n",
      "    self._train(\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 1705, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4585, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4634, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:26: Can't create train tmp dir: tmp\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 5007, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 2278, in _fit\n",
      "    self._train(\n",
      "  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 1705, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4585, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4634, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: C:/Program Files (x86)/Go Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.88714286 0.87857143\n",
      " 0.89142857 0.88857143 0.88142857 0.88142857 0.90285714 0.90428571\n",
      " 0.88428571 0.88428571 0.89285714 0.89714286 0.88857143 0.88857143\n",
      " 0.89142857 0.9        0.88       0.89571429 0.89714286 0.91142857\n",
      " 0.89142857 0.90285714 0.90571429 0.91428571 0.89571429 0.9\n",
      " 0.90857143 0.91714286 0.89428571 0.90285714 0.91142857 0.91714286\n",
      " 0.89571429 0.90428571 0.91142857 0.91571429 0.88857143 0.89428571\n",
      " 0.90142857 0.89714286 0.9        0.89857143 0.90571429 0.90714286\n",
      " 0.89857143 0.89714286 0.90857143 0.90428571 0.90714286 0.90857143\n",
      " 0.91428571 0.91428571 0.90714286 0.91142857 0.91714286 0.91857143\n",
      " 0.90714286 0.91142857 0.91714286 0.91714286 0.90571429 0.91714286\n",
      " 0.92       0.91857143 0.91142857 0.91571429 0.91714286 0.91857143\n",
      " 0.91       0.91285714 0.91857143 0.91571429 0.90714286 0.91285714\n",
      " 0.91428571 0.91714286 0.89428571 0.89714286 0.89285714 0.89857143\n",
      " 0.90571429 0.9        0.90285714 0.9        0.90571429 0.90285714\n",
      " 0.90571429 0.90714286 0.90142857 0.90285714 0.90142857 0.91\n",
      " 0.90428571 0.90285714 0.90571429 0.90857143 0.90714286 0.90571429\n",
      " 0.90714286 0.91428571 0.91       0.91285714 0.90857143 0.91571429\n",
      " 0.91       0.91571429 0.91428571 0.91857143 0.91285714 0.91428571\n",
      " 0.91571429 0.91857143 0.91285714 0.91428571 0.91571429 0.92285714\n",
      " 0.89428571 0.90142857 0.89714286 0.90142857 0.89857143 0.91285714\n",
      " 0.90285714 0.90571429 0.89428571 0.9        0.90428571 0.90571429\n",
      " 0.89571429 0.90428571 0.90857143 0.91       0.90285714 0.90857143\n",
      " 0.91285714 0.91142857 0.90428571 0.91285714 0.91285714 0.91428571\n",
      " 0.91       0.91142857 0.91285714 0.91428571 0.91       0.91285714\n",
      " 0.91571429 0.91428571 0.91142857 0.91285714 0.91571429 0.91285714\n",
      " 0.90857143 0.91285714 0.91428571 0.91857143 0.9        0.9\n",
      " 0.89714286 0.90142857 0.91571429 0.91714286 0.91       0.91\n",
      " 0.90857143 0.91285714 0.91428571 0.91142857 0.90857143 0.91142857\n",
      " 0.90857143 0.91428571 0.90714286 0.91       0.91       0.91285714\n",
      " 0.91142857 0.91142857 0.91142857 0.91571429 0.91285714 0.91714286\n",
      " 0.91142857 0.91285714 0.91142857 0.91714286 0.91       0.91428571\n",
      " 0.91142857 0.91714286 0.91857143 0.91142857 0.91571429 0.92\n",
      " 0.91857143 0.91285714 0.90285714 0.89571429 0.90285714 0.9\n",
      " 0.91       0.91285714 0.90714286 0.91428571 0.90857143 0.91285714\n",
      " 0.90571429 0.90714286 0.91       0.91285714 0.90571429 0.91142857\n",
      " 0.90857143 0.91714286 0.90571429 0.90571429 0.90714286 0.91857143\n",
      " 0.91571429 0.91285714 0.91       0.91857143 0.91714286 0.91428571\n",
      " 0.91142857 0.91714286 0.91714286 0.91571429 0.91285714 0.91571429\n",
      " 0.92       0.91428571 0.91285714 0.91714286 0.91714286 0.91571429\n",
      " 0.90142857 0.90142857 0.90142857 0.90285714 0.90428571 0.90857143\n",
      " 0.90714286 0.91       0.9        0.90857143 0.90714286 0.90142857\n",
      " 0.90714286 0.90857143 0.90571429 0.90571429 0.90857143 0.90857143\n",
      " 0.90714286 0.91       0.91142857 0.91       0.90857143 0.91142857\n",
      " 0.91142857 0.91285714 0.90571429 0.91142857 0.91428571 0.91714286\n",
      " 0.90857143 0.91428571 0.91285714 0.91285714 0.91       0.91714286\n",
      " 0.91142857 0.91571429 0.91285714 0.91714286]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6749008\ttotal: 53.8ms\tremaining: 5.33s\n",
      "1:\tlearn: 0.6585933\ttotal: 55.9ms\tremaining: 2.74s\n",
      "2:\tlearn: 0.6428935\ttotal: 58.9ms\tremaining: 1.9s\n",
      "3:\tlearn: 0.6285031\ttotal: 61.4ms\tremaining: 1.47s\n",
      "4:\tlearn: 0.6121203\ttotal: 64.1ms\tremaining: 1.22s\n",
      "5:\tlearn: 0.5956805\ttotal: 66.2ms\tremaining: 1.04s\n",
      "6:\tlearn: 0.5813186\ttotal: 68ms\tremaining: 903ms\n",
      "7:\tlearn: 0.5668572\ttotal: 69.9ms\tremaining: 804ms\n",
      "8:\tlearn: 0.5530455\ttotal: 71.7ms\tremaining: 725ms\n",
      "9:\tlearn: 0.5409409\ttotal: 73.7ms\tremaining: 664ms\n",
      "10:\tlearn: 0.5285960\ttotal: 75.7ms\tremaining: 612ms\n",
      "11:\tlearn: 0.5168583\ttotal: 77.8ms\tremaining: 571ms\n",
      "12:\tlearn: 0.5049085\ttotal: 79.9ms\tremaining: 534ms\n",
      "13:\tlearn: 0.4960898\ttotal: 81.9ms\tremaining: 503ms\n",
      "14:\tlearn: 0.4866044\ttotal: 83.9ms\tremaining: 475ms\n",
      "15:\tlearn: 0.4757393\ttotal: 85.7ms\tremaining: 450ms\n",
      "16:\tlearn: 0.4668973\ttotal: 87.7ms\tremaining: 428ms\n",
      "17:\tlearn: 0.4579115\ttotal: 89.5ms\tremaining: 408ms\n",
      "18:\tlearn: 0.4491867\ttotal: 91.6ms\tremaining: 391ms\n",
      "19:\tlearn: 0.4413538\ttotal: 94ms\tremaining: 376ms\n",
      "20:\tlearn: 0.4327015\ttotal: 97ms\tremaining: 365ms\n",
      "21:\tlearn: 0.4251687\ttotal: 99.7ms\tremaining: 354ms\n",
      "22:\tlearn: 0.4190266\ttotal: 102ms\tremaining: 342ms\n",
      "23:\tlearn: 0.4116669\ttotal: 105ms\tremaining: 331ms\n",
      "24:\tlearn: 0.4052072\ttotal: 107ms\tremaining: 320ms\n",
      "25:\tlearn: 0.3986864\ttotal: 108ms\tremaining: 309ms\n",
      "26:\tlearn: 0.3914590\ttotal: 111ms\tremaining: 300ms\n",
      "27:\tlearn: 0.3856158\ttotal: 113ms\tremaining: 290ms\n",
      "28:\tlearn: 0.3794790\ttotal: 115ms\tremaining: 281ms\n",
      "29:\tlearn: 0.3740146\ttotal: 117ms\tremaining: 272ms\n",
      "30:\tlearn: 0.3685323\ttotal: 118ms\tremaining: 263ms\n",
      "31:\tlearn: 0.3625879\ttotal: 120ms\tremaining: 256ms\n",
      "32:\tlearn: 0.3581181\ttotal: 122ms\tremaining: 248ms\n",
      "33:\tlearn: 0.3525867\ttotal: 124ms\tremaining: 241ms\n",
      "34:\tlearn: 0.3476566\ttotal: 126ms\tremaining: 234ms\n",
      "35:\tlearn: 0.3426365\ttotal: 128ms\tremaining: 227ms\n",
      "36:\tlearn: 0.3377714\ttotal: 130ms\tremaining: 221ms\n",
      "37:\tlearn: 0.3330102\ttotal: 131ms\tremaining: 214ms\n",
      "38:\tlearn: 0.3281514\ttotal: 133ms\tremaining: 208ms\n",
      "39:\tlearn: 0.3240811\ttotal: 136ms\tremaining: 204ms\n",
      "40:\tlearn: 0.3201512\ttotal: 138ms\tremaining: 199ms\n",
      "41:\tlearn: 0.3161651\ttotal: 142ms\tremaining: 196ms\n",
      "42:\tlearn: 0.3124960\ttotal: 145ms\tremaining: 192ms\n",
      "43:\tlearn: 0.3086562\ttotal: 148ms\tremaining: 189ms\n",
      "44:\tlearn: 0.3044907\ttotal: 151ms\tremaining: 184ms\n",
      "45:\tlearn: 0.3005943\ttotal: 153ms\tremaining: 180ms\n",
      "46:\tlearn: 0.2968477\ttotal: 155ms\tremaining: 175ms\n",
      "47:\tlearn: 0.2934916\ttotal: 158ms\tremaining: 171ms\n",
      "48:\tlearn: 0.2900401\ttotal: 160ms\tremaining: 166ms\n",
      "49:\tlearn: 0.2864068\ttotal: 162ms\tremaining: 162ms\n",
      "50:\tlearn: 0.2830513\ttotal: 164ms\tremaining: 158ms\n",
      "51:\tlearn: 0.2797474\ttotal: 166ms\tremaining: 153ms\n",
      "52:\tlearn: 0.2768256\ttotal: 169ms\tremaining: 150ms\n",
      "53:\tlearn: 0.2740952\ttotal: 172ms\tremaining: 147ms\n",
      "54:\tlearn: 0.2713712\ttotal: 175ms\tremaining: 143ms\n",
      "55:\tlearn: 0.2683745\ttotal: 177ms\tremaining: 139ms\n",
      "56:\tlearn: 0.2654853\ttotal: 179ms\tremaining: 135ms\n",
      "57:\tlearn: 0.2627543\ttotal: 181ms\tremaining: 131ms\n",
      "58:\tlearn: 0.2599230\ttotal: 183ms\tremaining: 127ms\n",
      "59:\tlearn: 0.2571456\ttotal: 185ms\tremaining: 123ms\n",
      "60:\tlearn: 0.2546724\ttotal: 188ms\tremaining: 120ms\n",
      "61:\tlearn: 0.2522471\ttotal: 190ms\tremaining: 116ms\n",
      "62:\tlearn: 0.2497000\ttotal: 191ms\tremaining: 112ms\n",
      "63:\tlearn: 0.2473323\ttotal: 193ms\tremaining: 109ms\n",
      "64:\tlearn: 0.2447753\ttotal: 195ms\tremaining: 105ms\n",
      "65:\tlearn: 0.2423129\ttotal: 196ms\tremaining: 101ms\n",
      "66:\tlearn: 0.2398476\ttotal: 198ms\tremaining: 97.5ms\n",
      "67:\tlearn: 0.2375610\ttotal: 199ms\tremaining: 93.9ms\n",
      "68:\tlearn: 0.2356330\ttotal: 201ms\tremaining: 90.5ms\n",
      "69:\tlearn: 0.2337056\ttotal: 203ms\tremaining: 87.1ms\n",
      "70:\tlearn: 0.2314301\ttotal: 205ms\tremaining: 83.7ms\n",
      "71:\tlearn: 0.2294756\ttotal: 207ms\tremaining: 80.3ms\n",
      "72:\tlearn: 0.2271429\ttotal: 208ms\tremaining: 77ms\n",
      "73:\tlearn: 0.2247836\ttotal: 210ms\tremaining: 73.8ms\n",
      "74:\tlearn: 0.2230158\ttotal: 212ms\tremaining: 70.8ms\n",
      "75:\tlearn: 0.2211962\ttotal: 215ms\tremaining: 67.8ms\n",
      "76:\tlearn: 0.2190639\ttotal: 217ms\tremaining: 65ms\n",
      "77:\tlearn: 0.2172550\ttotal: 219ms\tremaining: 61.8ms\n",
      "78:\tlearn: 0.2152986\ttotal: 221ms\tremaining: 58.7ms\n",
      "79:\tlearn: 0.2133950\ttotal: 223ms\tremaining: 55.6ms\n",
      "80:\tlearn: 0.2114308\ttotal: 224ms\tremaining: 52.6ms\n",
      "81:\tlearn: 0.2100609\ttotal: 226ms\tremaining: 49.5ms\n",
      "82:\tlearn: 0.2086878\ttotal: 227ms\tremaining: 46.5ms\n",
      "83:\tlearn: 0.2067866\ttotal: 229ms\tremaining: 43.6ms\n",
      "84:\tlearn: 0.2048225\ttotal: 231ms\tremaining: 40.8ms\n",
      "85:\tlearn: 0.2031245\ttotal: 233ms\tremaining: 37.9ms\n",
      "86:\tlearn: 0.2017262\ttotal: 235ms\tremaining: 35.1ms\n",
      "87:\tlearn: 0.2001494\ttotal: 237ms\tremaining: 32.3ms\n",
      "88:\tlearn: 0.1987154\ttotal: 239ms\tremaining: 29.6ms\n",
      "89:\tlearn: 0.1975144\ttotal: 242ms\tremaining: 26.9ms\n",
      "90:\tlearn: 0.1960904\ttotal: 245ms\tremaining: 24.3ms\n",
      "91:\tlearn: 0.1948481\ttotal: 248ms\tremaining: 21.6ms\n",
      "92:\tlearn: 0.1932988\ttotal: 251ms\tremaining: 18.9ms\n",
      "93:\tlearn: 0.1920432\ttotal: 254ms\tremaining: 16.2ms\n",
      "94:\tlearn: 0.1906991\ttotal: 256ms\tremaining: 13.5ms\n",
      "95:\tlearn: 0.1891869\ttotal: 258ms\tremaining: 10.7ms\n",
      "96:\tlearn: 0.1877224\ttotal: 259ms\tremaining: 8.02ms\n",
      "97:\tlearn: 0.1865944\ttotal: 261ms\tremaining: 5.33ms\n",
      "98:\tlearn: 0.1854891\ttotal: 264ms\tremaining: 2.66ms\n",
      "99:\tlearn: 0.1839616\ttotal: 266ms\tremaining: 0us\n",
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " <catboost.core.CatBoostClassifier object at 0x000002CC0C884C70>\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9228571428571428\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'depth': 6, 'iterations': 100, 'learning_rate': 0.04}\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "CBC = CatBoostClassifier()\n",
    "parameters = {'depth'         : [4,5,6,7,8,9, 10],\n",
    "              'learning_rate' : [0.01,0.02,0.03,0.04],\n",
    "              'iterations'    : [10, 20,30,40,50,60,70,80,90, 100]\n",
    "                 }\n",
    "Grid_CBC = GridSearchCV(estimator=CBC, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "Grid_CBC.fit(x_train, y_train)\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",Grid_CBC.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",Grid_CBC.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",Grid_CBC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2850b414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6749008\ttotal: 2.15ms\tremaining: 213ms\n",
      "1:\tlearn: 0.6585933\ttotal: 4.36ms\tremaining: 213ms\n",
      "2:\tlearn: 0.6428935\ttotal: 6.32ms\tremaining: 204ms\n",
      "3:\tlearn: 0.6285031\ttotal: 8.79ms\tremaining: 211ms\n",
      "4:\tlearn: 0.6121203\ttotal: 10.9ms\tremaining: 208ms\n",
      "5:\tlearn: 0.5956805\ttotal: 12.7ms\tremaining: 200ms\n",
      "6:\tlearn: 0.5813186\ttotal: 14.8ms\tremaining: 197ms\n",
      "7:\tlearn: 0.5668572\ttotal: 16.6ms\tremaining: 191ms\n",
      "8:\tlearn: 0.5530455\ttotal: 19.1ms\tremaining: 193ms\n",
      "9:\tlearn: 0.5409409\ttotal: 21.2ms\tremaining: 191ms\n",
      "10:\tlearn: 0.5285960\ttotal: 23.5ms\tremaining: 190ms\n",
      "11:\tlearn: 0.5168583\ttotal: 26.1ms\tremaining: 191ms\n",
      "12:\tlearn: 0.5049085\ttotal: 28.9ms\tremaining: 193ms\n",
      "13:\tlearn: 0.4960898\ttotal: 30.8ms\tremaining: 189ms\n",
      "14:\tlearn: 0.4866044\ttotal: 33.7ms\tremaining: 191ms\n",
      "15:\tlearn: 0.4757393\ttotal: 36.1ms\tremaining: 190ms\n",
      "16:\tlearn: 0.4668973\ttotal: 38.1ms\tremaining: 186ms\n",
      "17:\tlearn: 0.4579115\ttotal: 39.6ms\tremaining: 181ms\n",
      "18:\tlearn: 0.4491867\ttotal: 41.3ms\tremaining: 176ms\n",
      "19:\tlearn: 0.4413538\ttotal: 43.3ms\tremaining: 173ms\n",
      "20:\tlearn: 0.4327015\ttotal: 45.1ms\tremaining: 170ms\n",
      "21:\tlearn: 0.4251687\ttotal: 47.1ms\tremaining: 167ms\n",
      "22:\tlearn: 0.4190266\ttotal: 49.1ms\tremaining: 164ms\n",
      "23:\tlearn: 0.4116669\ttotal: 51ms\tremaining: 161ms\n",
      "24:\tlearn: 0.4052072\ttotal: 52.6ms\tremaining: 158ms\n",
      "25:\tlearn: 0.3986864\ttotal: 54.1ms\tremaining: 154ms\n",
      "26:\tlearn: 0.3914590\ttotal: 55.7ms\tremaining: 151ms\n",
      "27:\tlearn: 0.3856158\ttotal: 57.6ms\tremaining: 148ms\n",
      "28:\tlearn: 0.3794790\ttotal: 60ms\tremaining: 147ms\n",
      "29:\tlearn: 0.3740146\ttotal: 61.6ms\tremaining: 144ms\n",
      "30:\tlearn: 0.3685323\ttotal: 63.7ms\tremaining: 142ms\n",
      "31:\tlearn: 0.3625879\ttotal: 65.3ms\tremaining: 139ms\n",
      "32:\tlearn: 0.3581181\ttotal: 66.8ms\tremaining: 136ms\n",
      "33:\tlearn: 0.3525867\ttotal: 68.7ms\tremaining: 133ms\n",
      "34:\tlearn: 0.3476566\ttotal: 70.5ms\tremaining: 131ms\n",
      "35:\tlearn: 0.3426365\ttotal: 72.1ms\tremaining: 128ms\n",
      "36:\tlearn: 0.3377714\ttotal: 73.8ms\tremaining: 126ms\n",
      "37:\tlearn: 0.3330102\ttotal: 75.6ms\tremaining: 123ms\n",
      "38:\tlearn: 0.3281514\ttotal: 77.1ms\tremaining: 121ms\n",
      "39:\tlearn: 0.3240811\ttotal: 78.8ms\tremaining: 118ms\n",
      "40:\tlearn: 0.3201512\ttotal: 80.3ms\tremaining: 116ms\n",
      "41:\tlearn: 0.3161651\ttotal: 81.8ms\tremaining: 113ms\n",
      "42:\tlearn: 0.3124960\ttotal: 83.4ms\tremaining: 111ms\n",
      "43:\tlearn: 0.3086562\ttotal: 84.9ms\tremaining: 108ms\n",
      "44:\tlearn: 0.3044907\ttotal: 86.4ms\tremaining: 106ms\n",
      "45:\tlearn: 0.3005943\ttotal: 88ms\tremaining: 103ms\n",
      "46:\tlearn: 0.2968477\ttotal: 89.5ms\tremaining: 101ms\n",
      "47:\tlearn: 0.2934916\ttotal: 91ms\tremaining: 98.6ms\n",
      "48:\tlearn: 0.2900401\ttotal: 92.5ms\tremaining: 96.3ms\n",
      "49:\tlearn: 0.2864068\ttotal: 94.1ms\tremaining: 94.1ms\n",
      "50:\tlearn: 0.2830513\ttotal: 95.6ms\tremaining: 91.9ms\n",
      "51:\tlearn: 0.2797474\ttotal: 97.1ms\tremaining: 89.6ms\n",
      "52:\tlearn: 0.2768256\ttotal: 98.5ms\tremaining: 87.4ms\n",
      "53:\tlearn: 0.2740952\ttotal: 100ms\tremaining: 85.2ms\n",
      "54:\tlearn: 0.2713712\ttotal: 102ms\tremaining: 83.1ms\n",
      "55:\tlearn: 0.2683745\ttotal: 103ms\tremaining: 81ms\n",
      "56:\tlearn: 0.2654853\ttotal: 105ms\tremaining: 78.8ms\n",
      "57:\tlearn: 0.2627543\ttotal: 106ms\tremaining: 76.8ms\n",
      "58:\tlearn: 0.2599230\ttotal: 108ms\tremaining: 74.7ms\n",
      "59:\tlearn: 0.2571456\ttotal: 109ms\tremaining: 72.8ms\n",
      "60:\tlearn: 0.2546724\ttotal: 111ms\tremaining: 70.8ms\n",
      "61:\tlearn: 0.2522471\ttotal: 112ms\tremaining: 68.8ms\n",
      "62:\tlearn: 0.2497000\ttotal: 114ms\tremaining: 66.8ms\n",
      "63:\tlearn: 0.2473323\ttotal: 115ms\tremaining: 64.9ms\n",
      "64:\tlearn: 0.2447753\ttotal: 117ms\tremaining: 62.9ms\n",
      "65:\tlearn: 0.2423129\ttotal: 118ms\tremaining: 60.9ms\n",
      "66:\tlearn: 0.2398476\ttotal: 120ms\tremaining: 59ms\n",
      "67:\tlearn: 0.2375610\ttotal: 121ms\tremaining: 57ms\n",
      "68:\tlearn: 0.2356330\ttotal: 122ms\tremaining: 55ms\n",
      "69:\tlearn: 0.2337056\ttotal: 124ms\tremaining: 53.1ms\n",
      "70:\tlearn: 0.2314301\ttotal: 125ms\tremaining: 51.2ms\n",
      "71:\tlearn: 0.2294756\ttotal: 127ms\tremaining: 49.4ms\n",
      "72:\tlearn: 0.2271429\ttotal: 128ms\tremaining: 47.5ms\n",
      "73:\tlearn: 0.2247836\ttotal: 130ms\tremaining: 45.6ms\n",
      "74:\tlearn: 0.2230158\ttotal: 132ms\tremaining: 43.8ms\n",
      "75:\tlearn: 0.2211962\ttotal: 133ms\tremaining: 42ms\n",
      "76:\tlearn: 0.2190639\ttotal: 135ms\tremaining: 40.2ms\n",
      "77:\tlearn: 0.2172550\ttotal: 136ms\tremaining: 38.4ms\n",
      "78:\tlearn: 0.2152986\ttotal: 138ms\tremaining: 36.6ms\n",
      "79:\tlearn: 0.2133950\ttotal: 139ms\tremaining: 34.7ms\n",
      "80:\tlearn: 0.2114308\ttotal: 140ms\tremaining: 33ms\n",
      "81:\tlearn: 0.2100609\ttotal: 142ms\tremaining: 31.2ms\n",
      "82:\tlearn: 0.2086878\ttotal: 144ms\tremaining: 29.4ms\n",
      "83:\tlearn: 0.2067866\ttotal: 145ms\tremaining: 27.6ms\n",
      "84:\tlearn: 0.2048225\ttotal: 146ms\tremaining: 25.8ms\n",
      "85:\tlearn: 0.2031245\ttotal: 148ms\tremaining: 24.1ms\n",
      "86:\tlearn: 0.2017262\ttotal: 149ms\tremaining: 22.3ms\n",
      "87:\tlearn: 0.2001494\ttotal: 151ms\tremaining: 20.5ms\n",
      "88:\tlearn: 0.1987154\ttotal: 152ms\tremaining: 18.8ms\n",
      "89:\tlearn: 0.1975144\ttotal: 153ms\tremaining: 17.1ms\n",
      "90:\tlearn: 0.1960904\ttotal: 155ms\tremaining: 15.3ms\n",
      "91:\tlearn: 0.1948481\ttotal: 156ms\tremaining: 13.6ms\n",
      "92:\tlearn: 0.1932988\ttotal: 158ms\tremaining: 11.9ms\n",
      "93:\tlearn: 0.1920432\ttotal: 159ms\tremaining: 10.2ms\n",
      "94:\tlearn: 0.1906991\ttotal: 161ms\tremaining: 8.46ms\n",
      "95:\tlearn: 0.1891869\ttotal: 162ms\tremaining: 6.76ms\n",
      "96:\tlearn: 0.1877224\ttotal: 164ms\tremaining: 5.06ms\n",
      "97:\tlearn: 0.1865944\ttotal: 165ms\tremaining: 3.37ms\n",
      "98:\tlearn: 0.1854891\ttotal: 166ms\tremaining: 1.68ms\n",
      "99:\tlearn: 0.1839616\ttotal: 168ms\tremaining: 0us\n",
      "93.33333333333333\n",
      "[[144  12]\n",
      " [  8 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       156\n",
      "           1       0.92      0.94      0.93       144\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cbc = CatBoostClassifier(depth = 6,iterations = 100 ,learning_rate = 0.04)\n",
    "cbc.fit(x_train,y_train)\n",
    "y_pred = cbc.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "001f0c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9242857142857142, Best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 300, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbr = GradientBoostingClassifier(random_state=42)\n",
    "gbr_params = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [50, 80, 100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3, 5],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "gbr_search = GridSearchCV(gbr, param_grid=gbr_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "gbr_search.fit(x_train, y_train)\n",
    "best_mse = gbr_search.best_score_\n",
    "best_rmse = best_mse\n",
    "\n",
    "print('Best score: {}, Best params: {}'.format(best_rmse, gbr_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6d6032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.33333333333334\n",
      "[[146  10]\n",
      " [  7 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       156\n",
      "           1       0.93      0.95      0.94       144\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 3, min_samples_leaf = 1, min_samples_split = 3, n_estimators = 300,random_state=42)\n",
    "gbr.fit(x_train,y_train)\n",
    "y_pred = gbr.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57658514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9214285714285714, Best params: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500, 'num_leaves': 25, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "lgbm_params = {\n",
    "    'num_leaves': [25, 31, 35],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5],\n",
    "    'n_estimators': [100, 300, 500, 1000],\n",
    "    'max_depth': [3, 7, 11],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "lgbm_search = GridSearchCV(lgbm, param_grid=lgbm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "lgbm_search.fit(x_train, y_train)\n",
    "best_mse = lgbm_search.best_score_\n",
    "best_rmse = best_mse\n",
    "\n",
    "print('Best score: {}, Best params: {}'.format(best_rmse, lgbm_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c2fe1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.33333333333334\n",
      "[[148   8]\n",
      " [  6 138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       156\n",
      "           1       0.95      0.96      0.95       144\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(learning_rate = 0.05, max_depth = 3, n_estimators = 500, num_leaves = 25,random_state=42)\n",
    "lgbm.fit(x_train,y_train)\n",
    "y_pred = lgbm.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed507df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9286, Best params: {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3, 5],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "rf_search = GridSearchCV(rf, param_grid=rf_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rf_search.fit(x_train, y_train)\n",
    "best_mse = rf_search.best_score_\n",
    "best_rmse = best_mse\n",
    "\n",
    "print('Best score: {}, Best params: {}'.format(round(best_rmse, 4), rf_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00f698d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.33333333333334\n",
      "[[149   7]\n",
      " [ 10 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       156\n",
      "           1       0.95      0.93      0.94       144\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth = 9, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 500, random_state = 42)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred) * 100)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7c333d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/projects/ML/Classified Data/scaler.h5']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(clf,'D:/projects/ML/Classified Data/model.h5')\n",
    "joblib.dump(scaler,'D:/projects/ML/Classified Data/scaler.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a6ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
